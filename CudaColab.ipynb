{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ktm3JkI7vrnR"
      },
      "source": [
        "# CUDA on Colab\n",
        "\n",
        "This notebook, based on an example from Nvidia, shows how to check the GPU status of your Colab notebook, check out a github repository containing your c++ code, and compile it using either g++ for CPU or nvcc for GPU. and run it.\n",
        "\n",
        "Not yet covered, profiling.\n",
        "\n",
        "Author: Evelyn Mitchell\n",
        "Source Repository: https://github.com/evelynmitchell/cuda-on-colab\n",
        "Date: 2023-12-04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fsj6QjYwFtx"
      },
      "source": [
        "The nvidia-smi cli tells you about your GPU. The sample outputs for different types of GPUs or TPUs follow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ-Pv2U5IKTJ"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00ulMfjWJMUH"
      },
      "source": [
        "A100 GPU\n",
        "```\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpxfIJiUI_c9"
      },
      "source": [
        "V100 GPU\n",
        "```\n",
        "Mon Dec  4 18:42:36 2023       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   31C    P0    23W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tTpRQF-IikI"
      },
      "source": [
        "T4 TPU\n",
        "```\n",
        "Mon Dec  4 18:40:38 2023       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   48C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN1nWSaHKUVf"
      },
      "source": [
        "# C++ for CUDA\n",
        "Install the c++ build chain, which should be already available on colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKBGPAMsJ4Ji"
      },
      "outputs": [],
      "source": [
        "!apt install build-essential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-VVuTSdwVRJ"
      },
      "source": [
        "The GPU compiler for c++ from Nvidia is called nvcc, and is already installed on Colab, as is build-essential, which provides g++ as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZQLuKHZJ0hW"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjUMM5ygKngM"
      },
      "source": [
        "## Get the code\n",
        "Checkout the repository containing the c++ files to compile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cD-OYMwKmoO"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/evelynmitchell/cuda-on-colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4LGcpR3Nm91"
      },
      "source": [
        "## Build the code for CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHSDLMN4Nmjg"
      },
      "outputs": [],
      "source": [
        "!g++ /content/cuda-on-colab/src/simple.cpp -o simple\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I5JZuBzPcnS"
      },
      "outputs": [],
      "source": [
        "!chmod +x ./simple\n",
        "!./simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3myEKLJzShQn"
      },
      "source": [
        "## Compile to a CUDA kernel\n",
        "\n",
        "Adding the  ```__global__``` specifier to a function indicates it will be compiled to a CUDA kernel and run on a GPU processor.\n",
        "\n",
        "This code fails when it's compiled due to an error in how it is called. The error and fix follow this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYgRPRX7Sbuf"
      },
      "outputs": [],
      "source": [
        "!nvcc /content/cuda-on-colab/src/simple_cuda.cu -o simple_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-7IdoPaTcJ7"
      },
      "outputs": [],
      "source": [
        "!chmod +x ./simple_cuda\n",
        "!./simple_cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0QUba4rrIgO"
      },
      "source": [
        "## Configure kernel launch\n",
        "\n",
        "The error from the prior version of the compilation \"__global__ function call must be configured\" is corrected by adding kernel launch parameters <<<gridsize,blocksize>>> to the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbGjUBb6rGdn"
      },
      "outputs": [],
      "source": [
        "!nvcc /content/cuda-on-colab/src/simple_cuda_kernel_launch.cu -o simple_cuda_kernal_launch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOo-qL2_t8Xi"
      },
      "outputs": [],
      "source": [
        "!chmod +x ./simple_cuda_kernal_launch\n",
        "!./simple_cuda_kernal_launch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./simple_cuda_kernal_launch"
      ],
      "metadata": {
        "id": "OeOa2oOjZYhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/cuda-on-colab/src/simple_cuda_memory_alloc.cu -o simple_cuda_memory_alloc\n"
      ],
      "metadata": {
        "id": "0_fXXIOJiye_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/simple_cuda_memory_alloc\n",
        "!nvprof ./simple_cuda_memory_alloc"
      ],
      "metadata": {
        "id": "5ozN41O-jCAi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}