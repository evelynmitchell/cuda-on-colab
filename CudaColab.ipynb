{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ-Pv2U5IKTJ"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A100 GPU\n",
        "```\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "00ulMfjWJMUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "V100 GPU\n",
        "```\n",
        "Mon Dec  4 18:42:36 2023       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   31C    P0    23W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```"
      ],
      "metadata": {
        "id": "IpxfIJiUI_c9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T4 TPU\n",
        "```\n",
        "Mon Dec  4 18:40:38 2023       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   48C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```"
      ],
      "metadata": {
        "id": "2tTpRQF-IikI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "pZQLuKHZJ0hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C++ for CUDA\n",
        "Install the c++ build chain, which should be already available on colab."
      ],
      "metadata": {
        "id": "XN1nWSaHKUVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install build-essential"
      ],
      "metadata": {
        "id": "DKBGPAMsJ4Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the code\n",
        "Checkout the repository containing the c++ file to compile."
      ],
      "metadata": {
        "id": "gjUMM5ygKngM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/evelynmitchell/cuda-on-colab"
      ],
      "metadata": {
        "id": "_cD-OYMwKmoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the code"
      ],
      "metadata": {
        "id": "z4LGcpR3Nm91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ /content/cuda-on-colab/src/simple.cpp -o simple\n"
      ],
      "metadata": {
        "id": "QHSDLMN4Nmjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x ./simple\n",
        "!./simple"
      ],
      "metadata": {
        "id": "5I5JZuBzPcnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile to a CUDA kernel\n",
        "\n",
        "Adding the  ```__global__``` specifier to a function indicates it will be compiled to a CUDA kernel and run on a GPU processor."
      ],
      "metadata": {
        "id": "3myEKLJzShQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/cuda-on-colab/src/simple_cuda.cu -o simple_cuda"
      ],
      "metadata": {
        "id": "rYgRPRX7Sbuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x ./simple_cuda\n",
        "!./simple_cuda"
      ],
      "metadata": {
        "id": "m-7IdoPaTcJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure kernel launch\n",
        "\n",
        "The error from the prior version of the compilation \"__global__ function call must be configured\" is corrected by adding kernel launch parameters <<<gridsize,blocksize>>> to the function."
      ],
      "metadata": {
        "id": "K0QUba4rrIgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/cuda-on-colab/src/simple_cuda_kernel_launch.cu -o simple_cuda_kernal_launch"
      ],
      "metadata": {
        "id": "pbGjUBb6rGdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x ./simple_cuda_kernal_launch\n",
        "!./simple_cuda_kernal_launch"
      ],
      "metadata": {
        "id": "zOo-qL2_t8Xi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}